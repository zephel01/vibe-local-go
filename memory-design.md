# コンテキスト記憶機能 設計メモ

> 作成日: 2026-02-23 | 対象: vibe-local-go
> 参考: https://github.com/thedotmack/claude-mem

## 課題

セッションをまたいだコンテキスト（プロジェクトの知識、ユーザーの好み、過去の決定事項）が失われる。
毎回ゼロから説明し直す必要がある。

---

## 参考: claude-mem の仕組み

- ライフサイクルフック（セッション開始/終了/ツール使用後）で「観察」を自動記録
- SQLite + Chroma（ベクトルDB）でセマンティック検索
- Bunベースのワーカーサービス（ポート37777）
- 3層の段階的検索（トークン節約）
- Claude Code 専用設計

---

## 実装方式の比較

### A: ネイティブ実装

| 項目 | 評価 |
|------|------|
| 外部依存ゼロ維持 | ◎ |
| オフライン完全動作 | ◎ |
| ローカルLLMの小コンテキスト最適化 | ◎ |
| ベクトル検索の実装コスト | △（自前実装 or 簡易検索で代替） |
| 他ツールとのメモリ共有 | ✕ |

### B: MCP経由

| 項目 | 評価 |
|------|------|
| 他ツール（Claude Code等）とメモリ共有 | ◎ |
| 既存実装の活用 | ○ |
| 追加プロセス（MCPサーバー）が必要 | △ |
| Bun/Node.js依存の復活 | ✕（哲学に反する） |
| オフラインセットアップの手間 | △ |

### C: ハイブリッド（推奨案）

ネイティブで軽量なメモリ機能を内蔵しつつ、MCP互換インターフェースもオプション公開。

```
コア: Go内蔵メモリストア（SQLite or JSON）
     ↓
  内部API（検索・保存・要約）
     ↓
  ├── エージェントが直接使う（ネイティブ、デフォルト）
  └── MCPサーバーとしても公開（オプション、将来対応）
```

単体でオフライン動作 + 将来MCPエコシステムに接続する余地を残す。

---

## 重要な論点: ローカルLLMでセマンティック検索は実用的か？

claude-memはChroma（ベクトルDB）+ エンベディングモデルを使用。
しかしローカルLLMのコンテキストが8Kしかない環境で、追加のエンベディングモデルを走らせるメモリ余裕があるかは疑問。

### 段階的アプローチ（推奨）

| 段階 | 検索方式 | 必要リソース |
|------|---------|-------------|
| Phase 1 | キーワード検索 + 直近セッション要約 | なし（Go標準ライブラリのみ） |
| Phase 2 | TF-IDF的な関連度スコアリング | なし（自前実装） |
| Phase 3 | ベクトル検索（余裕がある環境のみ） | エンベディングモデル（~500MB） |

---

## 現行vibe-goのセッション管理（活用可能な既存機能）

- セッション永続化: JSONL形式、プロジェクトハッシュでの自動紐付け
- トークン推定: CJK対応済み
- コンパクション: 70%閾値での自動要約
- プロジェクト設定: `.vibe-coder.json` / `CLAUDE.md` 読み込み

---

## ステータス

**検討中** — 実装方式はハイブリッド(C)が有力。まずPhase 1（キーワード検索＋セッション要約）から。
