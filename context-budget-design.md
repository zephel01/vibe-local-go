# コンテキスト予算管理 設計メモ

> 作成日: 2026-02-23 | 対象: vibe-local-go
> 最終更新: 2026-02-23

## 大前提: ターゲットユーザー

**素人に近い、「AIコーディングを試してみよう」という人**。
コンテキストウィンドウやトークンの概念を知らない。設定なしで動くことが最優先。

設計原則:
- ユーザーは `vibe-local` と打つだけ。設定不要。
- 裏で全自動調整。ユーザーにはコンテキスト管理を意識させない。
- 問題が起きたら自動で代替方法を試す。それでも無理なら平易な日本語で伝える。

---

## 課題

ローカルLLMはコンテキストウィンドウが小さい（8K / 16K / 32K トークン）。
opencode等の既存ツールでは、ツール出力がコンテキストを圧迫して処理不能になる問題が未解決。

### 具体的な破綻パターン

```
コンテキスト: 8,192 tokens
- システムプロンプト:  ~2,000 tokens
- 会話履歴:           ~1,500 tokens
- ツール定義:         ~1,500 tokens
- 残り予算:           ~3,192 tokens
- ツール出力（30KB）:  ~7,500 tokens ← ここで破綻
```

ツール出力の截断サイズ（現在は固定30KB）がコンテキストウィンドウサイズに連動していないことが根本原因。

### 日本語トークン効率問題

日本語は英語の約2倍のトークンを消費する。

```
"このファイルのバグを修正してください" → ~16トークン（1文字≒1トークン）
"Please fix the bug in this file"     → ~8トークン
```

ctx=8192環境では日本語ユーザーの実効予算は英語ユーザーの約半分。
対策: システムプロンプトは英語で記述（LLMへの指示は英語の方が精度も高い）。
ユーザーへの応答言語は日本語のまま。

### 現行コードの問題点（5件）

1. **`GetContextWindow()` がハードコード**: compaction.go で常に 32768 を返す。configの値が未使用。
2. **ツール出力の截断が固定値**: bash=30KB, read=2000行, grep=500件。ctx非連動。
3. **コンパクションがツール結果追加「後」**: 既にコンテキスト溢れた後にチェック。
4. **LLM呼び出し前に予算チェックなし**: 溢れたまま送信して破綻。
5. **ツールが予算情報にアクセスする手段がない**: Execute(ctx, params) のIF。

---

## 設計方針

### ツール出力截断: A+C ハイブリッド

**Phase 1: エージェント側截断（方式C）**
- ツールは従来通りのIFで動作（変更不要）
- エージェントがツール結果を受け取った後に予算内に截断
- 既存の固定上限（bash 30KB, read 2000行）はメモリ保護として残す
- 即効性あり。既存コード変更最小。

```go
// agent.go
result := tool.Execute(ctx, params)            // ツールはそのまま
result.Output = a.budgetMgr.TruncateToFit(result.Output)  // エージェント側で截断
```

**Phase 2: context.Value 経由でツールに予算を渡す（方式A）**
- bash, read, grep に予算を context.Context 経由で渡す
- ツールが「最初から予算内の量だけ読む」ようにする
- メモリ効率の改善（巨大データをメモリに展開してから捨てる無駄を排除）
- ツールIFの変更は不要（context.Value を使うため）

```go
// 予算を context に埋め込む
ctx = WithBudget(ctx, budget)

// ツール側で取得（nilならフォールバック）
func (t *BashTool) Execute(ctx context.Context, params json.RawMessage) (*Result, error) {
    budget := GetBudget(ctx)
    maxOutput := budget.ToolOutputLimit()  // 動的に調整
}
```

Tool IF変更（方式B）は全ツール書き換えのコストに見合わないため不採用。

### コンパクション: 二重チェック

1. **ツール結果追加時**: 簡易チェック（閾値超えたらフラグ立て）
2. **LLM呼び出し前**: 最終チェック（実際にコンパクション実行）

```
送信前チェック:
  total = system_prompt + tool_defs + messages + tool_results
  if total > context_window * 0.9:
    1. 古いツール結果を要約 or 削除
    2. 会話履歴をコンパクション
    3. それでも超えるならツール結果を強制截断
    4. 最終手段: エラーとして報告（破綻より良い）
```

---

## 小コンテキスト自動適応（ctx別戦略）

ユーザーが何もしなくても、ctxサイズに応じて自動的に動作モードが切り替わる。

### 戦略マトリクス

| ctx サイズ | A: 履歴圧縮 | B: 分割読み込み | C: プロンプト軽量化 | D: 昇格提案 |
|-----------|:-----------:|:--------------:|:------------------:|:-----------:|
| < 8K      | ◎ 全力    | ◎ 常時       | ◎ 全力           | 必要時     |
| 8K-16K    | ○ 発動    | ○ 発動       | △ 部分的         | 必要時     |
| 16K-32K   | △ 必要時  | △ 必要時     | ✕               | 必要時     |
| ≥ 32K     | △ 必要時  | ✕            | ✕               | ✕         |

### 戦略A: アグレッシブ履歴圧縮

ツール結果を次のターンが終わったら即座に要約に置き換える。

```
通常モード (ctx≥16K):
  Turn 1: Read file → 結果3000字そのまま保持
  Turn 2: Edit file → 結果500字そのまま保持
  Turn 3: 両方の結果が履歴に残っている

小ctx モード (ctx<16K):
  Turn 1: Read file → 結果3000字
  Turn 2: Edit file → Turn 1の結果を "Read: main.go (500行, Go)" に圧縮
  Turn 3: Turn 1は要約だけ、Turn 2の結果は次ターンで圧縮
```

常に直近1ターンのツール結果だけフルで保持。過去は要約。
LLMが再度必要なら自分でReadを呼び直す。

### 戦略B: スマート分割読み込み

大きなファイルを一度に読まず、概要→詳細の段階的アクセス。

```
LLM: Read("main.go")
エージェント: (ファイルが500行、予算は200行分)
  → 先頭50行 + 末尾50行 + 構造概要を返す:

  "ファイルは500行です。構造:
     1-30:    import
     31-120:  func main()
     121-250: func handleRequest()
     251-400: func processData()
     401-500: tests
   詳細は offset と limit を指定してください"
```

ctx=8Kでも500行のファイルを扱える。ターン数は増えるが作業は成立する。

### 戦略C: システムプロンプト・ツール定義軽量化

ctx が小さいとき、自動で軽量版に切り替え。

```
通常モード (ctx≥16K):
  システムプロンプト: ~2000 tokens（詳細ルール、例示、多言語）
  ツール定義: 15ツール全部 ~1500 tokens

小ctx モード (ctx<16K):
  システムプロンプト: ~500 tokens（最小限ルール、英語のみ）
  ツール定義: 必須6ツール(bash,read,write,edit,glob,grep) ~400 tokens

  → 差分 2600 tokens がツール出力・会話に使える（残り予算がほぼ倍）
```

### 戦略D: 自動コンテキスト昇格提案

作業内容がctxに対して大きすぎると判断したら:

1. まず自動で代替方法を試す（関数単位に分割して作業など）
2. それでも無理なら平易な日本語でユーザーに伝える

```
"このファイル(500行)は大きいので、関数ごとに分けて作業しますね。
 まず main() から見ていきます。"
```

最終フォールバック（自動代替も不可能な場合）:

```
"この作業は今の環境だと難しいです。
 もう少し小さいファイルで試すか、
 作業を分けてやってみましょうか？"
```

---

## コンテキストウィンドウ自動選択

### 起動時の自動決定（ユーザー設定不要）

```
RAM検出 → モデルサイズ算出 → KVキャッシュ余裕計算 → ctx決定
```

KVキャッシュのメモリ消費目安:

| モデル | ctx=4096 | ctx=8192 | ctx=16384 | ctx=32768 |
|--------|----------|----------|-----------|-----------|
| 8B (q4) | ~1GB | ~2GB | ~4GB | ~8GB |
| 14B (q4) | ~1.5GB | ~3GB | ~6GB | ~12GB |
| 30B (q4) | ~3.5GB | ~7GB | ~14GB | ~28GB |

### プリセット + 数値直指定（上級者向け）

デフォルトは全自動。上級者は直接指定も可能。

```bash
# 全自動（デフォルト、推奨）
vibe-local

# プリセット指定
vibe-local --speed      # ctx小さめ、高速応答優先
vibe-local --balanced   # バランス（自動選択と同等）
vibe-local --quality    # ctx大きめ、品質優先（メモリ余裕がある環境向け）

# 数値直指定（上級者）
vibe-local --context-window 16384
```

プリセットは内部的に数値に展開される:

| プリセット | ctx 決定方法 | 想定ユーザー |
|-----------|-------------|------------|
| --speed | 自動選択値の50% | 速度重視、短い作業 |
| --balanced | 自動選択値そのまま | デフォルトと同等 |
| --quality | 自動選択値の150%（メモリ上限まで） | 大きいファイルを扱いたい |

### メモリ不足時の挙動

要求されたctxがメモリに収まらない場合:

1. **自動縮小 + 警告表示**:
   ```
   ⚠ メモリが足りないため、コンテキストを 32768 → 8192 に調整しました。
      大きなファイルの作業は分割して行います。
   ```
2. `--force` フラグで上書き可能（自己責任）
3. エラー停止はしない（初心者が詰まる原因になる）

---

## ユーザーが遭遇する問題と自動対処

| ユーザーの体験 | 原因 | 自動対処 |
|--------------|------|---------|
| 返答が途中で切れる | max_tokens不足 or ctx溢れ | コンパクション + リトライ |
| 指示と全然違うことをする | プロンプト+ツール定義でctx大半使用 | 小ctxモードでプロンプト軽量化 |
| すごく遅い | ctxが大きすぎてスワップ落ち | 起動時の自動調整で防止 |
| 長く使ってると壊れる | 履歴蓄積でctx圧迫 | アグレッシブ履歴圧縮 |
| 大きいファイルが扱えない | ファイル全体がctxに収まらない | 分割読み込み + 段階的作業 |

---

## 動的予算計算

### 予算計算式

```
残り予算 = コンテキストウィンドウ
         - システムプロンプト（トークン）
         - ツール定義（トークン）
         - 会話履歴（トークン）
         - max_tokens（LLM応答の予約分）
         - 安全マージン（10%）

ツール出力上限 = 残り予算 × 0.6  （複数ツール同時呼び出し対応）
```

### コンテキストウィンドウ別の目安

| コンテキスト | 予算概算 | ツール出力上限 | 文字数目安 |
|-------------|---------|--------------|-----------|
| 4,096       | ~1,500  | ~900 tokens  | ~3,600字  |
| 8,192       | ~3,000  | ~1,800 tokens | ~7,200字  |
| 16,384      | ~8,000  | ~4,800 tokens | ~19,200字 |
| 32,768      | ~20,000 | ~12,000 tokens | ~48,000字 |

### 截断の優先順位

1. 中間省略（先頭 + 末尾を保持）— Bash出力向き
2. 末尾切り捨て（先頭を保持）— ファイル読み取り向き
3. 構造概要 + 部分表示 — 大きなファイル向き（戦略B）

---

## UI: 右パネル（リアルタイム表示）

Crush風の右パネルでコンテキスト使用状況をリアルタイム表示。
通常時は簡易、`--debug` 時は詳細。

### 通常モード

```
┌─ Context ──────────┐
│ 4.2K / 8K  (52%)   │
│ ████████░░░░░░░░░░  │
└────────────────────┘
```

### Debug モード

```
┌─ Context ──────────────────┐
│ 4,218 / 8,192 tokens (51%) │
│ ██████████░░░░░░░░░░░░░░░  │
│                             │
│ system:    2,014  (25%)     │
│ tools def: 1,487  (18%)     │
│ history:     512  ( 6%)     │
│ last out:    205  ( 3%)     │
│ ─────────────────────       │
│ remaining: 3,974  (49%)     │
│                             │
│ msgs: 12  compact: 0        │
│ truncated: 0  warnings: 0   │
└─────────────────────────────┘
```

### 警告色

| 使用率 | 色 | 動作 |
|--------|-----|------|
| 0-60%  | 緑  | 正常 |
| 60-80% | 黄  | 注意（コンパクション候補） |
| 80-90% | 赤  | 自動コンパクション発動 |
| 90%+   | 赤点滅 | 強制截断 + 警告メッセージ |

---

## 実装順序

1. **バックエンド: 予算計算エンジン** — 残りトークン予算を正確に計算する関数群
2. **バックエンド: エージェント側截断（Phase 1）** — ツール結果返却時に予算内に収める
3. **バックエンド: 送信前チェック + 二重コンパクション** — LLM呼び出し前のオーバーフロー防止
4. **バックエンド: 小ctx自動適応** — 戦略A〜D の自動発動ロジック
5. **バックエンド: context.Value経由のツール予算渡し（Phase 2）** — メモリ効率改善
6. **フロントエンド: 右パネルUI** — 予算計算エンジンの数値を表示

---

## 関連ファイル（現行コード）

| ファイル | 役割 | 変更内容 |
|---------|------|---------|
| `internal/session/token.go` | トークン推定 | 活用（変更なし） |
| `internal/session/compaction.go` | コンパクション | 改善: GetContextWindow修正、二重チェック、履歴圧縮 |
| `internal/tool/bash.go` | Bash出力截断 | Phase 2: context.Value対応 |
| `internal/tool/file_read.go` | ファイル読み取り | Phase 2: context.Value対応 + 構造概要モード |
| `internal/tool/grep.go` | Grep結果 | Phase 2: context.Value対応 |
| `internal/agent/agent.go` | エージェントループ | 送信前チェック追加、エージェント側截断 |
| `internal/config/memory.go` | コンテキスト自動選択 | 活用 + プリセット対応 |
| `internal/config/prompt.go` | システムプロンプト | 軽量版プロンプト追加 |
| `internal/ui/` | 右パネル | 新規追加 |
| 新規: `internal/budget/` | 予算管理エンジン | 新規パッケージ |
